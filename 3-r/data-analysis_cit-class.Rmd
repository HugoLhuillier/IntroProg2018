---
title: "Introduction to Programming"
subtitle: "<h3> *R: Data Analysis (creating, importing, tidying)* </h3>"
author: Hugo Lhuillier
date: Master in Economics, Sciences Po
output: 
  revealjs::revealjs_presentation:
    center: true 
    highlight: pygments
    # in class use 
    css: my-style-class.css
    # css: my-style.css
    transition: slide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', warning = F)
```
```{r, include = FALSE}
require(tidyverse)
require(nycflights13)
require(gapminder)
require(Lahman)
require(gridExtra)
require(ggthemes)
# for class
theme_set(theme_dark())
```

# `RStudio` projects

## `RStudio` projects

- How to organize your work? 
- Should keep all the files of a project together (input data, R scripts, analytical results, figures)
- `RStudio` built-in support: _projects_

## Creating a project 

- `File` $\rightarrow$ `New Project` $\rightarrow$ `New Directory` $\rightarrow$ `Empty project`
- Give it a **good name**, and a **good location** that you'll remember 

## `RStudio` projects' features 

- `R` automatically set the working directory to the emplacement of the project 
- Enter the following command, call it `diamonds.R`, and run the code 

```{r, eval = F}
library(tidyverse)
ggplot(diamonds, aes(carat, price)) +
  geom_hex()
ggsave("diamonds.pdf")
write_csv(diamonds, "diamonds.csv")
```

- Look in the folder containing the project, contains `.Rproj` file that saves everything useful.
- **Test**: quit `RStudio`, and double-click on the `.Rproj` file: back where you left off (same package, same command history, same data etc.)

# Creation (`tibble`) 

## Creation of `tibble`s

- Transform any data frame in a `tibble` via `as_tibble(<your_data_frame>)`
- Alternatively, can create `tibble` from sratch with `tibble()`

```{r}
tibble(
  x = 1:5,
  y = 1,         # automatically recycle inputs of length 1
  z = x ^ 2 + y  # can refer to the variables already created
)
```

## Creation of `tibble`s

- Alternatively again, can create `tibble` from sratch with `tribble()`

```{r}
tribble(
  # column headings are defined by formulas
  ~x, ~y, ~z,
  #--|--|----
  # entries are separated by commas
  "a", 2, 3.6,
  "b", 1, 8.5
)
```

## Subsetting 

- Possible to pull out a specific variable in two ways: `$` (only by name) and `[[]]` (by name and position)
```{r}
df <- tibble(
  x = runif(5),
  y = rnorm(5)
)
df$x      == df[["x"]]
df[["x"]] == df[[1]]
```
- To subset in a pipe, need to use `.`
```{r}
df %>% .$x == df %>% .[["x"]]
```

# Import (`readr`)

## `readr`’s basic functions 

- `read_csv()`: comma-delimited files; `read_csv2()`: semicolon-separated files; `read_tsv()` reads tab-delimited files; `read_delim()` reads in files with any delimiter
- `read_fwf()`: fixed-width files
- `read_log()`: Apache style log files
- Focus here on `read_csv()` (_note the `_` instead of `.` in Base `R`)

## Reading `csv` file with `read_csv()`

- As for `read.csv` the first argument is the path to the file to read 
- Can also supply an inline CSV file
- By default: uses the first line of the data for the column names
    
    - Possible to skip lines of metadata at the top of the file with `skip`
    - Can precise if the `csv` file has no column names with `col_names`
    
```{r}
read_csv("The first line of metadata
x,y,z
1,2,3", skip = 1)
read_csv("1,2,3\n4,5,6", col_names = FALSE)
```

## Reading `csv` file with `read_csv()`

- Possible to specify the `col_names` manually 
```{r}
read_csv("1,2,3\n4,5,6", col_names = c("x", "y", "z"))
```
- Possible to tell `R` what `NA` looks like
```{r}
read_csv("a,b,c\n1,2,.", na = ".")
```

## Parsing a file 

- When you `read_csv()`, `R` automatically guesses the data type of each column
```{r}
guess_parser("2010-10-01")
guess_parser(c("1", "5", "9"))
```
- How could it go wrong? `R` identifies the data types by looking at the first 1,000 rows. Problems if:

    1. the first 1,000 rows are a special case 
    1. the first 1,000 rows feature manu `NA`
    
## Parsing a complicated file: example 

```{r, warnings = TRUE}
challenge <- read_csv(readr_example("challenge.csv"))
problems(challenge)
```
<!--  two printed outputs: 
1. the column specification generated by looking at the first 1000 rows
1. the first five parsing failures -->

## Parsing a complicated file: overriding the default behavior 

- To override the default behavior, can specify manually the column specification 
```{r, warnings = TRUE}
challenge <- read_csv(
  readr_example("challenge.csv"),
  col_types = cols(
    x = col_double(),
    y = col_character()
    )
  )
```

## Parsing a complicated file: overriding the default behavior 

- Are we done? 
```{r}
problems(challenge)
tail(challenge)
```

## Parsing a complicated file: overriding the default behavior 

- Are we done? 
```{r}
problems(challenge)
tail(challenge)
challenge <- read_csv(
  readr_example("challenge.csv"),
  col_types = cols(
    x = col_double(),
    y = col_date()
    )
  )
```

## Parsing a complicated file: overriding the default behavior 

- If want to be really strict, use `stop_for_problems()`: throw an error and stop if there are any
parsing problems
- `readr` provides several useful parsers, with tons of options 

    - `col_logical()` and `col_integer()`
    - `col_double()` is a strict numeric parser, and `col_number()`
    - `col_character()`
    - `col_factor()`
    - `col_datetime()`, `col_date()`, and `col_time()`
    
## Writing to a file 

- Two basic functions to write data back to disk: `write_csv()` and `write_tsv()`
```{r}
write_csv(challenge, "challenge.csv")
# more options:
# write_csv(challenge, "challenge.csv", na = "NA", append = FALSE)
```
- Unfortunately, type information is lost when writing to csv file 
```{r}
read_csv("challenge.csv")
```

## Writing to a file: alternatives 

- Previous feature makes CSVs unreliable for caching interim results
- Alternartives 
    
    - `write_rds()` and `read_rds()`: store data in `R`’s custom binary format called RDS
    - `write_feather()` and `read_feather()` from the `feather` package implements a fast binary file format that can be shared across programming language
    
```{r}
write_rds(challenge, "challenge.rds")
read_rds("challenge.rds")
```

# Tidy (`tidyr`)

## Tidy dataset 

- Tidy dataset satisfies three interrelated requirements

    1. Each variable must have its own column
    1. Each observation must have its own row
    1. Each value must have its own cell 

- Two common problems

    1.One variable might be spread across multiple columns
    1. One observation might be scattered across multiple rows
    
## Tidying dataset: gathering (ex.)

```{r}
table1     # tidy
table4a    # only cases, differentiating the year 
table4b    # only population, differentiating the year 
```

## Tidying dataset: gathering 

- **Problem #1**: dataset where some of the column names values of a variable
- Solution: gather those columns into a new pair of variables
```{r}
table4a
# tidying 
table4a %>%
  gather(`1999`, `2000`, key = "year", value = "cases")
```
<!-- In the final result, the gathered columns are dropped, and we get
new key and value columns -->

## Tidying dataset: gathering 

- **Ex**: proceed similarly with table4b

## Tidying dataset: gathering 

- **Ex**: proceed similarly with table4b
```{r}
table4b %>%
  gather(`1999`, `2000`, key = "year", value = "population")
```

## Tidying dataset: gathering 

- Final step: combine the two tidied dataset, with `left_joint()`
```{r}
tidy4a <- table4a %>%
  gather(`1999`, `2000`, key = "year", value = "cases")
tidy4b <- table4b %>%
  gather(`1999`, `2000`, key = "year", value = "population")
left_join(tidy4a, tidy4b)
```

## Tidying dataset: spreading (ex.)

```{r}
table1 
table2
```
<!-- 
in table2: type column is useless: an
observation is a country in a year, but each observation is spread
across two rows
-->

## Tidying dataset: spreading 


- **Problem #2**: observations are scattered across multiple rows
```{r}
spread(table2, key = type, value = count)
```
<!-- key: the column to use to create new variables (as in variables names). value: the columns to use to fill the new columns created-->

## Tidying dataset: separating 

- `separate()` pulls apart one column into multiple columns, by splitting wherever a separator character appears
```{r}
# example
table3
```

## Tidying dataset: separating 

- To separate the `rate` column into `cases` and `population`: 
```{r}
table3 %>% 
  separate(rate, into = c("cases","population"))
```
- By default, `separate()` splits values wherever it sees a nonalphanumeric character 
- Possible to pass the separating character as argument 
```{r, eval = F}
table3 %>% 
  separate(rate, into = c("cases","population"), sep = "/")
```

## Tidying dataset: separating 

- By default, `separate()` leaves the data type of the column as is; override the default behavior with `convert = TRUE`
```{r, eval = F}
table3 %>% 
  separate(rate, into = c("cases","population"), convert = T)
```

## Tidying dataset: separating 

- Alternatively, can pass a vector of integers to `sep`, that `R` interprets as positions to split at
- Positive values start at 1 on the far left of the strings; negative values start at –1 on the far right of the strings
```{r}
table3 %>%
  separate(year, into = c("century", "year"), sep = 2)
```

## Tidying dataset: uniting 

- `unite()` combines multiple columns into a single column
```{r}
table5
table5 %>%
  unite(new, century, year)
```

## Tidying dataset: uniting 

- By default, `unite()` places an underscore between the values from different columns
- This can be overriden with the `sep` argument
```{r}
table5 %>%
  unite(new, century, year, sep = "")
```

## Tidying dataset: missing values 

- How many missing values are these in this dataset? 
```{r, echo = FALSE}
stocks <- tibble(
  year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr = c( 1, 2, 3, 4, 2, 3, 4),
  return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)
)
```
```{r}
stocks
```

## Tidying dataset: missing values 

- Missing values can be of two types:

    - explicitly missing: flagged with `NA`
    - implicitly missing: not present in the data
    
- To make implicity missing values explicit, use `complete()`: takes a set of columns, and finds all unique combinations, ensuring that the dataset contains all those values; otherwise, fills in explicit `NA`s where necessary

```{r}
stocks %>%
  complete(year, qtr)
```

## Tidying dataset: missing values

- Sometimes, missing values are also used to indicate that the previous value should be carried forward
```{r}
treatment <- tribble(
  ~ person, ~ treatment, ~response,
  "Derrick Whitmore", 1, 7,
  NA, 2, 10,
  NA, 3, 9,
  "Katherine Burke", 1, 4
)
```
- Can fill in these missing values with `fill()`: takes a set of columns where you want missing values to be replaced by the most recent non-missing value
```{r}
treatment %>%
  fill(person)
```


